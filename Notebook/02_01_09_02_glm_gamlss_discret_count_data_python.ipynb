{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/01_Generalized_Linear_Models_Python/blob/main/Notebook/02_01_09_02_glm_gamlss_discret_count_data_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oii9KTtuwpp"
      },
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1IFEWet-Aw4DhkkVe1xv_2YYqlvRe9m5_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-M2Zrq7uwpr"
      },
      "source": [
        "# 9.2 GAMLSS with Discrete Distributions\n",
        "\n",
        "Discrete distributions are probability distributions that describe the likelihood of outcomes for discrete random variables—variables that can take on a finite or countably infinite number of distinct values, typically non-negative integers (e.g., 0, 1, 2, ...). Unlike continuous distributions, which can take any value within a range, discrete distributions assign probabilities to specific points.\n",
        "\n",
        "**Key characteristics:**\n",
        "- The probability mass function (PMF) gives the probability for each possible value.\n",
        "- The cumulative distribution function (CDF) is the sum of probabilities up to a given value.\n",
        "- Common examples include:\n",
        "  - **Bernoulli**: Models a single trial with two outcomes (success/failure), e.g., coin flip.\n",
        "  - **Binomial**: Models the number of successes in a fixed number of independent Bernoulli trials.\n",
        "  - **Poisson**: Models the number of events occurring in a fixed interval of time or space, assuming rare events (e.g., number of emails received per hour).\n",
        "  - **Negative Binomial**: Models the number of trials needed to achieve a fixed number of successes, or the number of failures before successes; useful for overdispersed count data.\n",
        "  - **Geometric**: A special case of negative binomial, modeling trials until the first success.\n",
        "  - **Discrete Uniform**: Equal probability for a finite set of outcomes (e.g., rolling a die).\n",
        "\n",
        "These are widely used in fields like statistics, biology, and engineering for modeling count data, where values can't be fractional.\n",
        "\n",
        "## GAMLSS with Discrete Distributions and Smoothing\n",
        "\n",
        "This tutorial demonstrates how to use Generalized Additive Models for Location, Scale, and Shape (GAMLSS) in pure Python to model the `visits` variable from the `NMES1988` dataset with discrete distributions, incorporating smoothing terms for flexibility. Since there is no native full-featured GAMLSS package in Python equivalent to R's `gamlss`, we implement a flexible approximation using PyTorch for optimization and neural additive models (NAMs) to capture smooth effects. NAMs extend generalized additive models by using small neural networks for each feature's smooth function, allowing non-linear relationships while maintaining interpretability.\n",
        "\n",
        "We'll focus on Poisson (PO), Negative Binomial (NB, approximating NBI/NBII), and Zero-Inflated Negative Binomial (ZINB) distributions. The `visits` variable, representing the number of physician office visits, is a count variable suitable for these distributions to handle overdispersion and excess zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xKyOn05uwps"
      },
      "source": [
        "A `Neural Additive Model (NAM)` is a machine learning model that combines the interpretability of generalized additive models (GAMs) with the flexibility of neural networks. It is designed to model complex, non-linear relationships between features and the target variable while maintaining interpretability by representing the prediction as a sum of individual feature contributions. This makes NAMs particularly useful for tasks where understanding the impact of each feature is as important as predictive performance.\n",
        "\n",
        "In this Python tutorial on `Generalized Additive Models for Location, Scale, and Shape (GAMLSS)` with discrete distributions, the `NAM` is implemented to capture smooth, non-linear effects of continuous predictors (e.g., age, school, income) and linear effects of categorical predictors (e.g., health, afam, gender) in a GAMLSS framework. The NAM serves as a flexible replacement for the penalized B-splines (pb()) used in the original R tutorial, allowing the model to learn complex relationships while preserving the additive structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRyjmdyRuwpt"
      },
      "source": [
        "## Install Required Python Packages\n",
        "\n",
        "The following Python packages are required to run this notebook. Install them using pip:\n",
        "\n",
        "```bash\n",
        "pip install torch pandas numpy matplotlib seaborn scikit-learn statsmodels scipy\n",
        "```\n",
        "\n",
        "**Note:** PyTorch (`torch`) is used for model definition, distributions, and optimization. No additional external packages like `rpy2` are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_2s4hPPuwpt"
      },
      "source": [
        "## Load Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7DAxl9_uwpt",
        "outputId": "1d84a84d-8883-4454-b6c2-5110c35b4d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Poisson, NegativeBinomial, Bernoulli\n",
        "from torch.nn.functional import softplus\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYDMrzMHuwpv"
      },
      "source": [
        "## Data\n",
        "\n",
        "The `NMES1988` dataset is available in R's `AER` package, but for pure Python, we'll load it from a CSV (download from https://vincentarelbundock.github.io/Rdatasets/csv/AER/NMES1988.csv). We'll use a subset of variables:\n",
        "- **Response**: `visits` (number of physician office visits, non-negative integer, count data).\n",
        "- **Predictors**:\n",
        "  - `hospital`: Number of hospital stays (numeric, count).\n",
        "  - `health`: Self-reported health status (factor: poor, average, excellent).\n",
        "  - `chronic`: Number of chronic conditions (numeric, count).\n",
        "  - `age`: Age in years, scaled as (age - 65)/10 (numeric).\n",
        "  - `afam`: African American indicator (yes/no, factor).\n",
        "  - `gender`: Gender (male/female, factor).\n",
        "  - `married`: Marital status (yes/no, factor).\n",
        "  - `school`: Years of education (numeric).\n",
        "  - `income`: Family income in $10,000s (numeric).\n",
        "  - `employed`: Employment status (yes/no, factor).\n",
        "  - `insurance`: Private insurance status (yes/no, factor).\n",
        "  - `medicaid`: Medicaid coverage (yes/no, factor).\n",
        "\n",
        "We'll apply GAMLSS with smoothing on continuous predictors (`age`, `school`, `income`) using neural shape functions, and linear terms for others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tu5_ME8Euwpw"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "import pandas as pd\n",
        "url = 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/NMES1988.csv'\n",
        "df = pd.read_csv(url)\n",
        "df = df[['visits', 'hospital', 'health', 'chronic', 'age', 'afam', 'gender', 'married',\n",
        "         'school', 'income', 'employed', 'insurance', 'medicaid']].copy()\n",
        "\n",
        "# Scale age as (age - 65)/10 if not already\n",
        "if df['age'].max() > 10:\n",
        "    df['age'] = (df['age'] - 65) / 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thmZAEUXuwpw"
      },
      "source": [
        "## Explore the Data\n",
        "\n",
        "Summarize and inspect the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY_s-il-uwpw",
        "outputId": "85933bd5-cd69-4514-ffa5-da19d9caa50a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             visits     hospital   health      chronic          age  afam  \\\n",
            "count   4406.000000  4406.000000     4406  4406.000000  4406.000000  4406   \n",
            "unique          NaN          NaN        3          NaN          NaN     2   \n",
            "top             NaN          NaN  average          NaN          NaN    no   \n",
            "freq            NaN          NaN     3509          NaN          NaN  3890   \n",
            "mean       5.774399     0.295960      NaN     1.541988    -5.759759   NaN   \n",
            "std        6.759225     0.746398      NaN     1.349632     0.063341   NaN   \n",
            "min        0.000000     0.000000      NaN     0.000000    -5.840000   NaN   \n",
            "25%        1.000000     0.000000      NaN     1.000000    -5.810000   NaN   \n",
            "50%        4.000000     0.000000      NaN     1.000000    -5.770000   NaN   \n",
            "75%        8.000000     0.000000      NaN     2.000000    -5.720000   NaN   \n",
            "max       89.000000     8.000000      NaN     8.000000    -5.410000   NaN   \n",
            "\n",
            "        gender married       school       income employed insurance medicaid  \n",
            "count     4406    4406  4406.000000  4406.000000     4406      4406     4406  \n",
            "unique       2       2          NaN          NaN        2         2        2  \n",
            "top     female     yes          NaN          NaN       no       yes       no  \n",
            "freq      2628    2406          NaN          NaN     3951      3421     4004  \n",
            "mean       NaN     NaN    10.290286     2.527132      NaN       NaN      NaN  \n",
            "std        NaN     NaN     3.738736     2.924648      NaN       NaN      NaN  \n",
            "min        NaN     NaN     0.000000    -1.012500      NaN       NaN      NaN  \n",
            "25%        NaN     NaN     8.000000     0.912150      NaN       NaN      NaN  \n",
            "50%        NaN     NaN    11.000000     1.698150      NaN       NaN      NaN  \n",
            "75%        NaN     NaN    12.000000     3.172850      NaN       NaN      NaN  \n",
            "max        NaN     NaN    18.000000    54.835100      NaN       NaN      NaN  \n"
          ]
        }
      ],
      "source": [
        "print(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Z9k9a-1Ruwpw",
        "outputId": "c0c1f8c9-b415-4fe1-fed3-ebc8c6e4a262"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df['visits'], bins=50, edgecolor='black')\n",
        "plt.title('Histogram of Physician Visits')\n",
        "plt.xlabel('Number of Visits')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nFSQOSVuwpx"
      },
      "source": [
        "- `visits` is a count variable (0, 1, 2, ...), often right-skewed with potential zeros. It ranges from 0 to a maximum (e.g., around 89 in this dataset).\n",
        "\n",
        "Check for overdispersion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2t9756luwpx",
        "outputId": "1c8b6a61-7186-4a37-941c-ba8bdbde5fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of visits: 5.774398547435315\n",
            "Variance of visits: 45.68711740207662\n",
            ">> Overdispersion detected (var > mean)\n"
          ]
        }
      ],
      "source": [
        "mean_visits = df['visits'].mean()\n",
        "var_visits = df['visits'].var()\n",
        "print(f\"Mean of visits: {mean_visits}\")\n",
        "print(f\"Variance of visits: {var_visits}\")\n",
        "if var_visits > mean_visits:\n",
        "    print(\">> Overdispersion detected (var > mean)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-wvqvAuwpx"
      },
      "source": [
        "Convert categorical variables to categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MQ8ds8cIuwpx"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['health', 'afam', 'gender', 'married', 'employed', 'insurance', 'medicaid']\n",
        "for col in categorical_cols:\n",
        "    df[col] = pd.Categorical(df[col], categories=df[col].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlvFaYueuwpx"
      },
      "source": [
        "Split data stratified by gender and afam:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gvmw98Qluwpy"
      },
      "outputs": [],
      "source": [
        "# Stratified split\n",
        "train, test = train_test_split(df, test_size=0.3, stratify=df[['gender', 'afam']], random_state=101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B9A8uzjuwpy"
      },
      "source": [
        "Check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siaFSB0muwpy",
        "outputId": "cca0c999-5a62-48b9-89f5-9ead267dda48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "visits       0\n",
            "hospital     0\n",
            "health       0\n",
            "chronic      0\n",
            "age          0\n",
            "afam         0\n",
            "gender       0\n",
            "married      0\n",
            "school       0\n",
            "income       0\n",
            "employed     0\n",
            "insurance    0\n",
            "medicaid     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())\n",
        "df = df.dropna()\n",
        "train = train.dropna()\n",
        "test = test.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZJ4JP6Ouwpy"
      },
      "source": [
        "Check for overdispersion in training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LwY8hjcuwpy",
        "outputId": "7909c3e4-5aa9-4a78-b02f-173d8e42b4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of visits (train): 5.841763942931258\n",
            "Variance of visits (train): 48.27012027380782\n",
            ">> Overdispersion detected (var > mean)\n"
          ]
        }
      ],
      "source": [
        "mean_train = train['visits'].mean()\n",
        "var_train = train['visits'].var()\n",
        "print(f\"Mean of visits (train): {mean_train}\")\n",
        "print(f\"Variance of visits (train): {var_train}\")\n",
        "if var_train > mean_train:\n",
        "    print(\">> Overdispersion detected (var > mean)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBQyo0y_uwpz"
      },
      "source": [
        "## Prepare Data Tensors\n",
        "\n",
        "Prepare features for NAM: continuous scaled, categoricals one-hot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "87ijCZmzuwp0"
      },
      "outputs": [],
      "source": [
        "continuous_features = ['age', 'school', 'income', 'hospital', 'chronic']\n",
        "categorical_features = ['health', 'afam', 'gender', 'married', 'employed', 'insurance', 'medicaid']\n",
        "\n",
        "# Scaler for continuous\n",
        "scaler = StandardScaler()\n",
        "train_cont = scaler.fit_transform(train[continuous_features])\n",
        "test_cont = scaler.transform(test[continuous_features])\n",
        "\n",
        "# One-hot for categorical\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "train_cat = encoder.fit_transform(train[categorical_features])\n",
        "test_cat = encoder.transform(test[categorical_features])\n",
        "cat_dims = [train_cat.shape[1]]  # Combined for simplicity\n",
        "\n",
        "# To dicts for NAM\n",
        "def prepare_data(cont_df, cat_arr):\n",
        "    cont_dict = {feat: torch.tensor(cont_df[:, i:i+1], dtype=torch.float32, device=device)\n",
        "                 for i, feat in enumerate(continuous_features)}\n",
        "    cat_dict = {'cats': torch.tensor(cat_arr, dtype=torch.float32, device=device)}\n",
        "    return cont_dict, cat_dict\n",
        "\n",
        "train_cont_dict, train_cat_dict = prepare_data(train_cont, train_cat)\n",
        "test_cont_dict, test_cat_dict = prepare_data(test_cont, test_cat)\n",
        "y_train = torch.tensor(train['visits'].values, dtype=torch.float32, device=device)\n",
        "y_test = torch.tensor(test['visits'].values, dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3u4zgVeuwpz"
      },
      "source": [
        "## Implement Neural Additive Model (NAM) Components\n",
        "\n",
        "We'll define a simple NAM using PyTorch: each continuous feature gets a small MLP for its shape function, categoricals get linear embeddings. The model for a parameter (e.g., mu) is the sum of shape functions plus bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRJAohNEuwpz"
      },
      "source": [
        "**Key Components of the NAM Implementation**\n",
        "\n",
        "`ShapeFunction (Per-Feature Model)`:\n",
        "\n",
        "* Each feature in the model has its own ShapeFunction, a small neural network (MLP) for continuous features or a linear layer for categorical features.\n",
        "\n",
        "* Continuous Features: A two-layer MLP (input → hidden → output) with ReLU activation captures non-linear relationships. For example, the effect of age on the expected number of physician visits (visits) is modeled as a smooth, non-linear function.\n",
        "\n",
        "* Categorical Features: A linear layer maps one-hot encoded categorical variables to their contribution. In the tutorial, for simplicity, all categorical features are combined into a single one-hot encoded input, but ideally, each categorical feature could have its own linear layer.\n",
        "\n",
        "`Additive Structure`:\n",
        "\n",
        "* The NAM combines the outputs of individual ShapeFunctions additively to produce the final prediction for a parameter (e.g., the log-mean mu_log for the Poisson or Negative Binomial distribution).\n",
        "\n",
        "* For a set of continuous features $x_1, x_2, \\ldots, x_m$ and categorical features $c_1, c_2, \\ldots, c_n$, the model output is:\n",
        "\n",
        "$$f(x, c) = \\text{bias} + f_1(x_1) + f_2(x_2) + \\cdots + f_m(x_m) + g_1(c_1) + g_2(c_2) + \\cdots + g_n(c_n)$$\n",
        "\n",
        "where $ f_i $ is the MLP for continuous feature $ x_i $, and $ g_j $ is the linear layer for categorical feature $ c_j $.\n",
        "\n",
        "\n",
        "`Role in GAMLSS`:\n",
        "\n",
        "* In the GAMLSS framework, the NAM is used to model distribution parameters (e.g., `mu` for mean, `alpha` for dispersion in Negative Binomial, `pi` for zero-inflation in ZINB).\n",
        "\n",
        "*  For example, in the `PoissonGAMLSS` model, the NAM predicts the log-mean (`mu_log`), which is exponentiated to get the Poisson rate parameter (`mu = torch.exp(mu_log`)).\n",
        "\n",
        "* Similarly, in the NBGAMLSS and ZINBGAMLSS models, separate NAMs are used for `mu`, `alpha`, and `pi` (for ZINB), allowing each parameter to depend on a subset of features with smooth or linear effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XnmfW3VAuwpz"
      },
      "outputs": [],
      "source": [
        "class ShapeFunction(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=8, is_continuous=True):\n",
        "        super().__init__()\n",
        "        if is_continuous:\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, 1)\n",
        "            )\n",
        "        else:\n",
        "            self.net = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NAM(nn.Module):\n",
        "    def __init__(self, continuous_features, cat_features, cat_dims, hidden_dim=8):\n",
        "        super().__init__()\n",
        "        self.continuous_nets = nn.ModuleDict({feat: ShapeFunction(1, hidden_dim, True) for feat in continuous_features})\n",
        "        self.categorical_nets = nn.ModuleDict({feat: ShapeFunction(dim, hidden_dim, False) for feat, dim in zip(cat_features, cat_dims)})\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, cont_data, cat_data):\n",
        "        total = self.bias.expand(len(next(iter(cont_data.values()))), 1)\n",
        "        for feat, net in self.continuous_nets.items():\n",
        "            total = total + net(cont_data[feat])  # Avoid in-place operation\n",
        "        for feat, net in self.categorical_nets.items():\n",
        "            total = total + net(cat_data[feat])  # Avoid in-place operation\n",
        "        return total.squeeze(1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0Z-sPnweuwpz"
      },
      "outputs": [],
      "source": [
        "class PoissonGAMLSS(nn.Module):\n",
        "    def __init__(self, cont_features, cat_dims):\n",
        "        super().__init__()\n",
        "        self.mu_net = NAM(cont_features, ['cats'], cat_dims)\n",
        "\n",
        "    def forward(self, cont_data, cat_data, y):\n",
        "        mu_log = self.mu_net(cont_data, cat_data)\n",
        "        mu = torch.exp(mu_log)\n",
        "        dist = Poisson(mu)\n",
        "        return -dist.log_prob(y).mean()  # Negative log-likelihood\n",
        "\n",
        "# Ensure model and data are on the same device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mod_po = PoissonGAMLSS(continuous_features, cat_dims).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53HZLae9uwp0",
        "outputId": "cdab8916-f251-41e6-cc26-f563cb34d889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model device: cpu\n",
            "train_cont_dict[age] device: cpu\n",
            "train_cont_dict[school] device: cpu\n",
            "train_cont_dict[income] device: cpu\n",
            "train_cont_dict[hospital] device: cpu\n",
            "train_cont_dict[chronic] device: cpu\n",
            "train_cat_dict['cats'] device: cpu\n",
            "y_train device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Verify tensor devices (for debugging)\n",
        "print(\"Model device:\", next(mod_po.parameters()).device)\n",
        "for feat, tensor in train_cont_dict.items():\n",
        "    print(f\"train_cont_dict[{feat}] device:\", tensor.device)\n",
        "print(\"train_cat_dict['cats'] device:\", train_cat_dict['cats'].device)\n",
        "print(\"y_train device:\", y_train.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofUPfSpzuwp0"
      },
      "source": [
        "## Fit GAMLSS Models on Training Data\n",
        "\n",
        "We'll fit models by maximizing the log-likelihood using Adam optimizer. For Poisson: model mu. For NB: model mu and alpha (dispersion, sigma = 1/sqrt(alpha)). For ZINB: add pi (zero-inflation prob)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F99iAj1Euwp0"
      },
      "source": [
        "### Poisson (PO) with Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpDpViKwuwp0",
        "outputId": "c9c81b5f-b222-4378-84af-b451002cdcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 9.5347\n",
            "Epoch 200, Loss: 4.0116\n",
            "Epoch 400, Loss: 4.0059\n",
            "Epoch 600, Loss: 4.0045\n",
            "Epoch 800, Loss: 4.0034\n",
            "Poisson model fitted.\n",
            "mu_net.bias: mean 0.1094, std nan\n",
            "mu_net.continuous_nets.age.net.0.weight: mean 0.1511, std 0.6514\n",
            "mu_net.continuous_nets.age.net.0.bias: mean -0.1270, std 0.6380\n",
            "mu_net.continuous_nets.age.net.2.weight: mean -0.1246, std 0.2106\n",
            "mu_net.continuous_nets.age.net.2.bias: mean -0.2340, std nan\n",
            "mu_net.continuous_nets.school.net.0.weight: mean 0.0647, std 0.6295\n",
            "mu_net.continuous_nets.school.net.0.bias: mean 0.5319, std 0.5568\n",
            "mu_net.continuous_nets.school.net.2.weight: mean 0.1269, std 0.1852\n",
            "mu_net.continuous_nets.school.net.2.bias: mean 0.3757, std nan\n",
            "mu_net.continuous_nets.income.net.0.weight: mean 0.1133, std 0.6881\n",
            "mu_net.continuous_nets.income.net.0.bias: mean -0.6160, std 0.2498\n",
            "mu_net.continuous_nets.income.net.2.weight: mean 0.1866, std 0.4214\n",
            "mu_net.continuous_nets.income.net.2.bias: mean -0.0889, std nan\n",
            "mu_net.continuous_nets.hospital.net.0.weight: mean -0.4105, std 0.5308\n",
            "mu_net.continuous_nets.hospital.net.0.bias: mean -0.0446, std 0.6070\n",
            "mu_net.continuous_nets.hospital.net.2.weight: mean -0.0364, std 0.1545\n",
            "mu_net.continuous_nets.hospital.net.2.bias: mean 0.0033, std nan\n",
            "mu_net.continuous_nets.chronic.net.0.weight: mean 0.2541, std 0.5042\n",
            "mu_net.continuous_nets.chronic.net.0.bias: mean 0.1941, std 0.7267\n",
            "mu_net.continuous_nets.chronic.net.2.weight: mean 0.0466, std 0.2898\n",
            "mu_net.continuous_nets.chronic.net.2.bias: mean -0.0124, std nan\n",
            "mu_net.categorical_nets.cats.net.weight: mean 0.0466, std 0.2284\n",
            "mu_net.categorical_nets.cats.net.bias: mean 0.4291, std nan\n"
          ]
        }
      ],
      "source": [
        "# Fit\n",
        "optimizer_po = optim.Adam(mod_po.parameters(), lr=0.01)\n",
        "for epoch in range(1000):\n",
        "    optimizer_po.zero_grad()\n",
        "    loss = mod_po(train_cont_dict, train_cat_dict, y_train)\n",
        "    loss.backward()\n",
        "    optimizer_po.step()\n",
        "    if epoch % 200 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Poisson model fitted.\")\n",
        "for name, param in mod_po.named_parameters():\n",
        "    print(f\"{name}: mean {param.data.mean().item():.4f}, std {param.data.std().item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEJBSJfFuwp1"
      },
      "source": [
        "### Negative Binomial (NB) with Smoothing\n",
        "\n",
        "For NB, use total_count=1 for simplicity (like NBI), alpha for dispersion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPxMlwxNuwp1",
        "outputId": "e71d4025-b68f-4e32-af42-1547e2c76d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 4.4119\n",
            "Epoch 200, Loss: 2.7649\n",
            "Epoch 400, Loss: 2.7641\n",
            "Epoch 600, Loss: 2.7637\n",
            "Epoch 800, Loss: 2.7634\n",
            "NB model fitted.\n"
          ]
        }
      ],
      "source": [
        "class NBGAMLSS(nn.Module):\n",
        "    def __init__(self, cont_features, cat_dims):\n",
        "        super().__init__()\n",
        "        self.mu_net = NAM(cont_features, ['cats'], cat_dims)\n",
        "        self.alpha_net = NAM(cont_features[:1], ['cats'], cat_dims)  # Simple for sigma ~ age + health\n",
        "\n",
        "    def forward(self, cont_data, cat_data, y):\n",
        "        mu_log = self.mu_net(cont_data, cat_data)\n",
        "        mu = torch.exp(mu_log)\n",
        "        alpha_log = self.alpha_net(cont_data, cat_data)\n",
        "        alpha = torch.exp(alpha_log)\n",
        "        dist = NegativeBinomial(total_count=torch.ones_like(y), logits=mu_log + alpha_log)\n",
        "        return -dist.log_prob(y).mean()\n",
        "\n",
        "mod_nb = NBGAMLSS(continuous_features, cat_dims).to(device)\n",
        "optimizer_nb = optim.Adam(mod_nb.parameters(), lr=0.01)\n",
        "for epoch in range(1000):\n",
        "    optimizer_nb.zero_grad()\n",
        "    loss = mod_nb(train_cont_dict, train_cat_dict, y_train)\n",
        "    loss.backward()\n",
        "    optimizer_nb.step()\n",
        "    if epoch % 200 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "print(\"NB model fitted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saw70bs5uwp1"
      },
      "source": [
        "### Zero-Inflated Negative Binomial (ZINB) with Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3FCR_Uzuwp1",
        "outputId": "84b53936-86e8-42cb-8e18-f68668fa3465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 10.9968\n",
            "Epoch 200, Loss: 2.7770\n",
            "Epoch 400, Loss: 2.7674\n",
            "Epoch 600, Loss: 2.7665\n",
            "Epoch 800, Loss: 2.7658\n",
            "ZINB model fitted.\n"
          ]
        }
      ],
      "source": [
        "class ZINBGAMLSS(nn.Module):\n",
        "    def __init__(self, cont_features, cat_dims):\n",
        "        super().__init__()\n",
        "        self.mu_net = NAM(cont_features, ['cats'], cat_dims)\n",
        "        self.alpha_net = NAM(cont_features[:1], ['cats'], cat_dims)\n",
        "        self.pi_net = NAM(['hospital'], ['cats'], cat_dims)  # Simple for nu ~ hospital + medicaid\n",
        "\n",
        "    def forward(self, cont_data, cat_data, y):\n",
        "        mu_log = self.mu_net(cont_data, cat_data)\n",
        "        mu = torch.exp(mu_log)\n",
        "        alpha_log = self.alpha_net(cont_data, cat_data)\n",
        "        alpha = torch.exp(alpha_log)\n",
        "        pi_logit = self.pi_net(cont_data, cat_data)\n",
        "        pi = torch.sigmoid(pi_logit)\n",
        "        nb_dist = NegativeBinomial(total_count=torch.ones_like(y), logits=mu_log + alpha_log)\n",
        "        ll_zero = torch.log(pi + (1 - pi) * torch.exp(nb_dist.log_prob(torch.zeros_like(y))))\n",
        "        ll_nonzero = torch.log(1 - pi + 1e-8) + nb_dist.log_prob(y)\n",
        "        ll = torch.where(y == 0, ll_zero, ll_nonzero)\n",
        "        return -ll.mean()\n",
        "\n",
        "mod_zinb = ZINBGAMLSS(continuous_features, cat_dims).to(device)\n",
        "optimizer_zinb = optim.Adam(mod_zinb.parameters(), lr=0.01)\n",
        "for epoch in range(1000):\n",
        "    optimizer_zinb.zero_grad()\n",
        "    loss = mod_zinb(train_cont_dict, train_cat_dict, y_train)\n",
        "    loss.backward()\n",
        "    optimizer_zinb.step()\n",
        "    if epoch % 200 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "print(\"ZINB model fitted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRUU2QNuwp2"
      },
      "source": [
        "**Notes:**\n",
        "- For Sichel and BB, similar extensions can be made, but omitted for brevity.\n",
        "- No convergence criterion like c.crit; fixed epochs. Add early stopping if needed.\n",
        "- Penalty for smoothing: Add L2 regularization in loss, e.g., `loss += 0.01 * sum(p.norm(2) for p in model.parameters())`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIetNE-Fuwp2"
      },
      "source": [
        "## Model Validation on Test Data\n",
        "\n",
        "Predict and evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4DgsYGKuwp2",
        "outputId": "691d0dd9-29c8-438d-fde5-6a75643e3927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           MSE   MAE  RMSE\n",
            "Poisson  35.78  4.04  5.98\n",
            "NB       42.52  3.96  6.52\n",
            "ZINB     36.73  3.91  6.06\n"
          ]
        }
      ],
      "source": [
        "def predict_model(model, cont_data, cat_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if 'PoissonGAMLSS' in str(type(model)):\n",
        "            mu = torch.exp(model.mu_net(cont_data, cat_data))\n",
        "            return mu.cpu().numpy().flatten()\n",
        "        elif 'NBGAMLSS' in str(type(model)):\n",
        "            mu_log = model.mu_net(cont_data, cat_data)\n",
        "            mu = torch.exp(mu_log)\n",
        "            return mu.cpu().numpy().flatten()\n",
        "        elif 'ZINBGAMLSS' in str(type(model)):\n",
        "            mu_log = model.mu_net(cont_data, cat_data)\n",
        "            mu = torch.exp(mu_log)\n",
        "            return mu.cpu().numpy().flatten()\n",
        "    return None\n",
        "\n",
        "def evaluate_model(model, test_cont, test_cat, y_test):\n",
        "    pred = predict_model(model, test_cont, test_cat)\n",
        "    mse = mean_squared_error(y_test.cpu(), pred)\n",
        "    mae = mean_absolute_error(y_test.cpu(), pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return {'MSE': mse, 'MAE': mae, 'RMSE': rmse}\n",
        "\n",
        "eval_po = evaluate_model(mod_po, test_cont_dict, test_cat_dict, y_test)\n",
        "eval_nb = evaluate_model(mod_nb, test_cont_dict, test_cat_dict, y_test)\n",
        "eval_zinb = evaluate_model(mod_zinb, test_cont_dict, test_cat_dict, y_test)\n",
        "\n",
        "eval_results = pd.DataFrame([eval_po, eval_nb, eval_zinb], index=['Poisson', 'NB', 'ZINB'])\n",
        "print(eval_results.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0riHwf-uwp2"
      },
      "source": [
        "- **Interpretation**: Lower MSE/MAE/RMSE indicates better fit. NB/ZINB should outperform Poisson due to overdispersion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnGU054guwp_"
      },
      "source": [
        "## Model Comparison on Training Data\n",
        "\n",
        "Approximate AIC: 2 * nll + 2 * num_params (on train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVSj3Zk0uwp_",
        "outputId": "feb3aece-3a07-4a51-c71c-4dd8a041bc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              AIC\n",
            "Poisson  24957.51\n",
            "NB       17384.25\n",
            "ZINB     17464.15\n"
          ]
        }
      ],
      "source": [
        "def approx_aic(model, cont_data, cat_data, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        nll = model(cont_data, cat_data, y).item() * len(y)  # Full nll\n",
        "        num_params = sum(p.numel() for p in model.parameters())\n",
        "        aic = 2 * nll + 2 * num_params\n",
        "        return aic\n",
        "\n",
        "aic_po = approx_aic(mod_po, train_cont_dict, train_cat_dict, y_train)\n",
        "aic_nb = approx_aic(mod_nb, train_cont_dict, train_cat_dict, y_train)\n",
        "aic_zinb = approx_aic(mod_zinb, train_cont_dict, train_cat_dict, y_train)\n",
        "\n",
        "aic_results = pd.DataFrame({'AIC': [aic_po, aic_nb, aic_zinb]}, index=['Poisson', 'NB', 'ZINB'])\n",
        "print(aic_results.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7jh2c0yuwp_"
      },
      "source": [
        "## Selecting the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBODtaQYuwp_",
        "outputId": "7d7cd896-eec3-4290-a5bc-c9c9190901bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model based on RMSE: Poisson\n",
            "Best model based on AIC: NB\n",
            "Different best models by RMSE and AIC. Consider context for final choice.\n"
          ]
        }
      ],
      "source": [
        "best_rmse = eval_results['RMSE'].idxmin()\n",
        "print(f\"Best model based on RMSE: {best_rmse}\")\n",
        "\n",
        "best_aic = aic_results['AIC'].idxmin()\n",
        "print(f\"Best model based on AIC: {best_aic}\")\n",
        "\n",
        "if best_rmse == best_aic:\n",
        "    print(f\"Selected best model: {best_rmse}\")\n",
        "else:\n",
        "    print(\"Different best models by RMSE and AIC. Consider context for final choice.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBx7IVrWuwp_"
      },
      "source": [
        "- NB or ZINB often best for overdispersed count data like `visits`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Une6JcrRuwqA"
      },
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "This tutorial demonstrates a pure Python implementation of GAMLSS-like models with discrete distributions using PyTorch for flexible neural additive smoothing on the `NMES1988` dataset. We used stratified splitting, neural shape functions for non-linear effects on continuous predictors, and torch.distributions for PMFs. Models for Poisson, Negative Binomial, and Zero-Inflated NB handle count data with overdispersion and zeros. NB/ZINB typically perform best. We evaluated with RMSE/AIC approximations, made predictions, plotted partial effects, and checked diagnostics.\n",
        "\n",
        "This approach is scalable and interpretable, extendable to more parameters/distributions. For production, consider adding penalties, early stopping, and custom distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ZX1rZBuwqA"
      },
      "source": [
        "## Resources\n",
        "\n",
        "1. **Flexible Regression and Smoothing: Using GAMLSS in R** (Stasinopoulos et al., 2017)\n",
        "   - [CRC Press](https://www.crcpress.com/9781138197909)\n",
        "   \n",
        "2. **Modeling Count Data** (Hilbe, 2014)\n",
        "   - [Cambridge](https://www.cambridge.org/9781107611252)\n",
        "   \n",
        "3. **PyTorch Distributions Documentation**\n",
        "   - [PyTorch Docs](https://pytorch.org/docs/stable/distributions.html)\n",
        "   \n",
        "4. **Neural Additive Models (for inspiration)**\n",
        "   - [Agarwal et al., 2021](https://arxiv.org/abs/2005.14188)\n",
        "   \n",
        "5. **PyTorch Tutorials on Custom Losses**\n",
        "   - [PyTorch Custom nn.Module](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_module.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.11.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}